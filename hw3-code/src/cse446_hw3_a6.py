# -*- coding: utf-8 -*-
"""cse446_hw3_a6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wMQV1BlCHBrWj8jnSL_if1u43x7lfAIO
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import os
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision as torchvision
import torchvision.datasets as datasets
import torchvision.models as models
import torch.utils.data as data
from torchvision import transforms
from tqdm import tqdm

# Constants 

device = "cuda" if torch.cuda.is_available() else "cpu"

valid_pct = 0.2
M_B = 100
M_C = 100
k = 5
N = 14

# Helpers and loading data

def get_dataset():

  transform = transforms.Compose(
      [transforms.ToTensor(),
      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

  trainset = datasets.CIFAR10(root='./data', train=True,
                                          download=True, transform=transform)
  trainset, validset = data.random_split(trainset, [int((1.0 - valid_pct) * len(trainset)),
                                                    int(valid_pct * len(trainset))])
  testset = datasets.CIFAR10(root='./data', train=False,
                                        download=True, transform=transform)

  return trainset, validset, testset

trainset, validset, testset = get_dataset()

def plot_acc(dataset, legends, filename, set_type, epochs=12):

  epoch_list = list(range(1, epochs + 1))

  print(dataset)

  for item in dataset:
    plt.plot(epoch_list, item)

  plt.title(set_type + " accuracy over time")
  plt.xlabel("epochs")
  plt.ylabel("accuracy")
  
  plt.legend(legends)

  plt.savefig(filename)

# Network definitions

# A_Net
class A_Net(nn.Module):
  def __init__(self):
    super().__init__()
    # Note that 3072 = 32 * 32 * 3, so need to flatten
    self.W = nn.Linear(3072, 10)

  def forward(self, x):
    x = x.view(-1, 32 * 32 * 3)
    return self.W(x)

# B_Net
class B_Net(nn.Module):
  def __init__(self, M_B=M_B):
    super().__init__()
    self.W1 = nn.Linear(3072, M_B)
    self.W2 = nn.Linear(M_B, 10)

  def forward(self, x):
    x = x.view(-1, 32 * 32 * 3)
    x = self.W1(x)
    x = F.relu(x)
    return self.W2(x)

# C_Net
class C_Net(nn.Module):
  def __init__(self, M=M_C, k=k, N=N):
    super().__init__()
    # 3 image input channels, M filters, kxk convolution
    self.conv = nn.Conv2d(3, M, k)
    self.pool = nn.MaxPool2d(N, N)
    # fc layer
    self.W2 = nn.Linear(int(M * ((int(33 - k) / int(N)) ** 2)), 10)

  def forward(self, x):
    x = F.relu(self.conv(x))
    x = self.pool(x)
    x = torch.flatten(x, start_dim=1, end_dim=3)
    return self.W2(x)

class D_Net(nn.Module):
    def __init__(self, c1, l1, l2):
        super().__init__()
        self.conv1 = nn.Conv2d(3, c1, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(c1, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, l1)
        self.fc2 = nn.Linear(l1, l2)
        self.fc3 = nn.Linear(l2, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = torch.flatten(x, 1) # flatten all dimensions except batch
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

def train(model, learning_rate, batch_size=100, momentum=0.9, epochs=12):

  trainloader = data.DataLoader(trainset, batch_size=batch_size,
                                shuffle=True, num_workers=2)
  validloader = data.DataLoader(validset, batch_size=batch_size,
                                shuffle=True, num_workers=2)

  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

  local_train_list = []
  local_valid_list = []

  for epoch in range(epochs):  # loop over the dataset multiple times

    train_correct = 0.0
    valid_correct = 0.0
    train_total = 0.0
    valid_total = 0.0

    torch.set_grad_enabled(True)
    model.train()

    # for inputs, labels in tqdm(trainloader):
    for inputs, labels in trainloader:

      inputs = inputs.to(device)
      labels = labels.to(device)

      # zero the parameter gradients
      optimizer.zero_grad()

      # forward + backward + optimize
      outputs = model.forward(inputs)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()
        
      train_total += labels.size(0)
      train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()
    
    torch.no_grad()
    model.eval()

    # for inputs, labels in tqdm(validloader):
    for inputs, labels in validloader:
      inputs = inputs.to(device)
      labels = labels.to(device)

      outputs = model.forward(inputs)
        
      valid_total += labels.size(0)
      valid_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()

    train_accuracy = train_correct / train_total
    valid_accuracy = valid_correct / valid_total

    print("Accuracy of the network on training data: " + str(train_accuracy))
    print("Accuracy of the network on validation data: " + str(valid_accuracy))

    local_train_list.append(train_accuracy)
    local_valid_list.append(valid_accuracy)

  return model, local_train_list, local_valid_list

def threshold_train(model, learning_rate, batch_size=100, momentum=0.9, threshold=0.7, both=False):
  
  trainloader = data.DataLoader(trainset, batch_size=batch_size,
                                shuffle=True, num_workers=2)
  validloader = data.DataLoader(validset, batch_size=batch_size,
                                shuffle=True, num_workers=2)

  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

  local_train_list = []
  local_valid_list = []

  while True:  # loop over the dataset multiple times

    train_correct = 0.0
    valid_correct = 0.0
    train_total = 0.0
    valid_total = 0.0

    torch.set_grad_enabled(True)
    model.train()

    # for inputs, labels in tqdm(trainloader):
    for inputs, labels in trainloader:

      inputs = inputs.to(device)
      labels = labels.to(device)

      # zero the parameter gradients
      optimizer.zero_grad()

      # forward + backward + optimize
      outputs = model.forward(inputs)
      loss = criterion(outputs, labels)
      loss.backward()
      optimizer.step()
        
      train_total += labels.size(0)
      train_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()
    
    torch.no_grad()
    model.eval()

    # for inputs, labels in tqdm(validloader):
    for inputs, labels in validloader:
      inputs = inputs.to(device)
      labels = labels.to(device)

      outputs = model.forward(inputs)
        
      valid_total += labels.size(0)
      valid_correct += (torch.argmax(outputs, dim=1) == labels).sum().item()

    train_accuracy = train_correct / train_total
    valid_accuracy = valid_correct / valid_total

    print("Accuracy of the network on training data: " + str(train_accuracy))
    print("Accuracy of the network on validation data: " + str(valid_accuracy))

    local_train_list.append(train_accuracy)
    local_valid_list.append(valid_accuracy)
    
    if (not both and (train_accuracy >= threshold or valid_accuracy >= threshold)):
      break
    
    if (both and (test(model) >= threshold)):
      break

  return model, local_train_list, local_valid_list

def test(model, batch_size=100):

  testloader = data.DataLoader(testset, batch_size=batch_size,
                               shuffle=False, num_workers=2)

  correct = 0.0
  total = 0.0

  # since we're not training, we don't need to calculate the gradients for our outputs
  with torch.no_grad():
    for batch in testloader:
      images, labels = batch

      images = images.to(device)
      labels = labels.to(device)

      # calculate outputs by running images through the network 
      outputs = model.forward(images)
      # the class with the highest energy is what we choose as prediction
      _, predicted = torch.max(outputs.data, 1)

      total += labels.size(0)
      correct += (torch.argmax(outputs, dim=1) == labels).sum().item()

    print("Accuracy of the network on test data: " + str(correct / total))

"""# part (a)"""

learning_rate_list = [10E-2, 10E-3, 10E-4]
batch_size_list = [5, 25, 100, 500]

legend_list = []
train_acc_list = []
valid_acc_list = []

# for loop through everything 
for learning_rate in learning_rate_list:
  for batch_size in batch_size_list:
    legend = "lr=%5.4f, bs=%d" % (learning_rate, batch_size)
    print(legend)
    legend_list.append(legend)

    model = A_Net()
    model.to(device)
    _, train_acc, valid_acc = train(model, learning_rate, batch_size)

    train_acc_list.append(train_acc)
    valid_acc_list.append(valid_acc)

print(legend_list)
print(train_acc_list)
print(valid_acc_list)

plot_acc(train_acc_list, legend_list, "a6_a_train.png", "training")
plot_acc(valid_acc_list, legend_list, "a6_a_valid.png", "validation")

lr=0.0010
bs=100

model = A_Net()
model.to(device)
model, train_acc, valid_acc = train(model, lr, bs)

print(train_acc)
print(valid_acc)

test(model, 100)

"""# part (b)"""

# As we learned from previous parts
batch_size = 100

learning_rate_list = [10E-3, 10E-4]
momentum_list = [0.8, 0.85, 0.9]
M_list = [100, 200, 300]

legend_list = []
train_acc_list = []
valid_acc_list = []

for learning_rate in learning_rate_list:
  for momentum in momentum_list:
    for M in M_list:
      legend = "lr=%5.4f, mom=%5.2f, M=%d" % (learning_rate, momentum, M)
      print(legend)
      legend_list.append(legend)

      model = B_Net(M)
      model.to(device)
      _, train_acc, valid_acc = train(model, learning_rate, momentum=momentum, batch_size=batch_size)

      train_acc_list.append(train_acc)
      valid_acc_list.append(valid_acc)

print(legend_list)
print(train_acc_list)
print(valid_acc_list)

plot_acc(train_acc_list, legend_list, "a6_b_train.png", "training")
plot_acc(valid_acc_list, legend_list, "a6_b_valid.png", "validation")

# evaluate your best set of hyperparameters on the test data and report the accuracy.

lr=0.0100
mom= 0.90
M=300

model = B_Net(M)
model.to(device)
model, train_acc, valid_acc = threshold_train(model, lr, momentum=mom)

print(train_acc)
print(valid_acc)

test(model)

"""# part (c)"""

# As we learned from previous parts
batch_size = 100

learning_rate_list = [10E-3, 10E-4]
momentum_list = [0.8, 0.85, 0.9]

legend_list = []
train_acc_list = []
valid_acc_list = []

for learning_rate in learning_rate_list:
  for momentum in momentum_list:
    legend = "lr=%5.4f, m=%5.2f" % (learning_rate, momentum)
    print(legend)
    legend_list.append(legend)

    model = C_Net(M_C, k, N)
    model.to(device)
    _, train_acc, valid_acc = train(model, learning_rate, momentum=momentum, batch_size=batch_size)

    train_acc_list.append(train_acc)
    valid_acc_list.append(valid_acc)

print(legend_list)
print(train_acc_list)
print(valid_acc_list)

plot_acc(train_acc_list, legend_list, "a6_c_train.png", "training")
plot_acc(valid_acc_list, legend_list, "a6_c_valid.png", "validation")

lr=0.0100
m= 0.90

model = C_Net(M_C, k, N)
model.to(device)
model, train_acc, valid_acc = threshold_train(model, lr, momentum=m)

print(train_acc)
print(valid_acc)

test(model)

"""# part (d)"""

# As we learned from previous parts
lr=0.0100
batch_size = 100

momentum_list = [0.8, 0.9]
l1_list = [120, 160]
l2_list = [84, 100]
c1_list = [16, 32]

legend_list = []
train_acc_list = []
valid_acc_list = []

for momentum in momentum_list:
  for l1 in l1_list:
    for l2 in l2_list:
      for c1 in c1_list:
        legend = "mom=%5.1f, l1=%d, l2=%d, c1=%d" % (momentum, l1, l2, c1)
        print(legend)
        legend_list.append(legend)

        model = D_Net(c1, l1, l2)
        model.to(device)
        _, train_acc, valid_acc = train(model, lr, momentum=momentum, batch_size=batch_size)

        train_acc_list.append(train_acc)
        valid_acc_list.append(valid_acc)

print(legend_list)
print(train_acc_list)
print(valid_acc_list)

plot_acc(train_acc_list, legend_list, "a6_d_train.png", "training")
plot_acc(valid_acc_list, legend_list, "a6_d_valid.png", "validation")

c1 = 32
l1 = 160
l2 = 100

m=0.80

model = D_Net(c1=32, l1=160, l2=100)
model.to(device)
model, train_acc, valid_acc = threshold_train(model, lr, momentum=m, both=True)

print(train_acc)
print(valid_acc)

test(model)